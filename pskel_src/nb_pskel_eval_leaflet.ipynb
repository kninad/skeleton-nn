{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "import utils.misc as workspace\n",
    "from SkelPointNet import SkelPointNet \n",
    "from DataUtil import LeafletData\n",
    "import FileRW as rw\n",
    "import DistFunc as DF\n",
    "import EvalUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"gt-full5000-pskel100-finetune_leaf\"\n",
    "experiment_dir = os.path.join(\"../experiments/\", EXP_NAME)\n",
    "checkpoint = 'latest'\n",
    "with open(os.path.join(experiment_dir, \"specs.json\"), \"r\") as f:\n",
    "    specs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_num = specs[\"InputPointNum\"]\n",
    "skelpoint_num = specs[\"SkelPointNum\"]\n",
    "to_normalize = specs[\"Normalize\"]\n",
    "gpu = \"0\"\n",
    "\n",
    "flag_sup = True  # supervision\n",
    "flags_vec = specs.get(\"FlagsVec\", [])\n",
    "if not flags_vec:\n",
    "    flags_vec = [0] * 4\n",
    "flags_boolvec = [x==1 for x in flags_vec]\n",
    "flag_spread, flag_radius, flag_medial, flag_spoke = flags_boolvec\n",
    "print(f\"FlagVec: {flags_vec}\")\n",
    "print(f\"FLAGS: {flag_spread}, {flag_radius}, {flag_medial}, {flag_spoke}!!!\")\n",
    "\n",
    "model_skel = SkelPointNet(\n",
    "    num_skel_points=skelpoint_num, input_channels=0, use_xyz=True,\n",
    "    flag_supervision=flag_sup,\n",
    "    flag_spread=flag_spread,\n",
    "    flag_radius=flag_radius,\n",
    "    flag_medial=flag_medial,\n",
    "    flag_spoke=flag_spoke\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "    print(\"GPU Number:\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_skel.cuda()\n",
    "    model_skel.eval()\n",
    "\n",
    "# Load the saved model\n",
    "model_epoch = workspace.load_model_checkpoint(\n",
    "    experiment_dir, checkpoint, model_skel\n",
    ")\n",
    "print(f\"Evaluating model on using checkpoint={checkpoint} and epoch={model_epoch}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and evaluate\n",
    "# Assume Training/Test split file (given as cmd line arg) will be present in the experiment dir\n",
    "data_dir = \"../data/leaflet_sreps/\"\n",
    "\n",
    "# For leaflets\n",
    "case_dirs = sorted(os.listdir(data_dir))\n",
    "data_list = [os.path.join(data_dir, case, \"warped_template.vtp\") for case in case_dirs]\n",
    "label_list = [os.path.join(data_dir, case, \"up_proc.vtp\") for case in case_dirs]\n",
    "\n",
    "idx_end = int(len(data_list) * 0.9)\n",
    "data_list_eval = data_list[idx_end:]\n",
    "label_list_eval = label_list[idx_end:]\n",
    "\n",
    "eval_data = LeafletData(\n",
    "    data_list_eval, label_list_eval, point_num, load_in_ram=True\n",
    ")\n",
    "\n",
    "EvalUtil.test_results(experiment_dir, eval_data, model_skel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pskel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca742bc1711152f0affa8d9004ce690f18a9c6fcba769975c923197a5a5ab50d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
