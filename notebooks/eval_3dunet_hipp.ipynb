{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43816cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from skimage import img_as_ubyte\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from monai.utils import set_determinism\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.utils import first\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss, DiceFocalLoss, FocalLoss\n",
    "from monai.networks.layers import Norm\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.transforms import AsDiscrete\n",
    "from monai.visualize.img2tensorboard import plot_2d_or_3d_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "libdir = \"../\"\n",
    "sys.path.insert(0, libdir)\n",
    "import utils.data\n",
    "from utils.data import get_surf_srep_split, get_srep_data_transform\n",
    "import utils.misc as workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff392bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"run4_1000_mod\"\n",
    "checkpoint = \"latest\"\n",
    "experiment_dir = os.path.join(libdir, \"experiments\", exp_name)\n",
    "\n",
    "# Setup the checkpoint and model eval dirs in exp_dir\n",
    "checkpt_dir = os.path.join(experiment_dir, workspace.checkpoint_subdir)\n",
    "eval_dir = os.path.join(experiment_dir, workspace.evaluation_subdir)\n",
    "if not os.path.isdir(checkpt_dir):\n",
    "    os.makedirs(checkpt_dir)\n",
    "if not os.path.isdir(eval_dir):\n",
    "    os.makedirs(eval_dir)\n",
    "\n",
    "with open(os.path.join(experiment_dir, \"specs.json\"), \"r\") as f:\n",
    "    specs = json.load(f)\n",
    "train_data_dir = specs[\"DataSource\"]\n",
    "learning_rate = specs[\"LearningRate\"]\n",
    "num_epochs = specs[\"Epochs\"]\n",
    "save_epoch = specs[\"SaveEvery\"]\n",
    "batch_size = specs[\"BatchSize\"]\n",
    "if_debug = specs[\"Debug\"]\n",
    "resize_shape = specs[\"ResizeShape\"]\n",
    "print(\n",
    "    f'Learning Rate:{learning_rate} | Epochs:{num_epochs} | BatchSize:{batch_size}')\n",
    "print(f\"Training data dir: {train_data_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373477c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = os.path.expanduser(train_data_dir)\n",
    "print(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9896cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = get_srep_data_transform((resize_shape, resize_shape, resize_shape))\n",
    "# trn_files, val_files, tst_files = get_surf_srep_split(train_data_dir, random_shuffle=False, debug=if_debug)\n",
    "# all_files = trn_files + val_files\n",
    "h_data_dir = \"../data/hippocampi/\"\n",
    "val_files = utils.data.get_hippocampi_files(h_data_dir)\n",
    "data_transforms = utils.data.get_hippocampi_transform((resize_shape, resize_shape, resize_shape))\n",
    "val_ds = CacheDataset(data=val_files, transform=data_transforms, cache_rate=0.8, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ")\n",
    "\n",
    "criterion1 = DiceLoss(sigmoid=True)\n",
    "criterion2 = FocalLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a9f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files[0]['fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model).cuda()\n",
    "model.eval()\n",
    "saved_epoch = workspace.load_model_checkpoint(experiment_dir, checkpoint, model)\n",
    "print(saved_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a76486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_ds[0]['image_meta_dict']\n",
    "eval_saving_dir = os.path.join(experiment_dir, workspace.evaluation_subdir)\n",
    "print(eval_saving_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f01921",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, val_data in tqdm(enumerate(val_loader)):\n",
    "        val_inp = val_data[\"image\"].to(device)\n",
    "        eval_file = val_data[\"fname\"][0] + \"_eval.npy\"\n",
    "        out_logits = model(val_inp)\n",
    "        out_img = torch.sigmoid(out_logits).detach().cpu()\n",
    "        np.save(os.path.join(eval_saving_dir, eval_file), out_img[0,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b0c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf4015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407ec8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb865be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SummaryWriter(eval_dir)\n",
    "with torch.no_grad():\n",
    "    for i, val_data in tqdm(enumerate(val_loader)):\n",
    "            val_inp = val_data[\"image\"].to(device)\n",
    "            val_lab = val_data[\"label\"].to(device)\n",
    "            out_logits = model(val_inp)\n",
    "            out_img = torch.sigmoid(out_logits).detach().cpu()\n",
    "            plot_2d_or_3d_image(data=val_lab, step=i, writer=sw, frame_dim=-1, tag='label')\n",
    "            plot_2d_or_3d_image(data=out_img, step=i, writer=sw, frame_dim=-1, tag='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c57999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, val_loader, device=torch.device(\"cuda:0\"), slice=80):\n",
    "    with torch.no_grad():\n",
    "        for i, val_data in enumerate(val_loader):\n",
    "            roi_size = (128, 128, 128)\n",
    "            sw_batch_size = 4\n",
    "            # val_outputs = sliding_window_inference(\n",
    "            #     val_data[\"image\"].to(device), roi_size, sw_batch_size, model\n",
    "            # )\n",
    "            # plot the slice [:, :, 10]\n",
    "            val_inp = val_data[\"image\"].to(device)\n",
    "            eval_file = val_data[\"fname\"][0] + \".npy\"\n",
    "            print(eval_file, val_data[\"fname\"][0])\n",
    "            # val_lab = val_data[\"label\"].to(device)\n",
    "            out_logits = model(val_inp)\n",
    "            out_img = torch.sigmoid(out_logits).detach().cpu()\n",
    "            # print(val_inp.shape, val_lab.shape, out_img.shape)\n",
    "            print(val_inp.shape, out_img.shape)\n",
    "            fig = plt.figure(\"check\", (18, 6))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.title(f\"image {i}\")\n",
    "            plt.imshow(val_data[\"image\"][0, 0, :, :, slice], cmap=\"gray\")\n",
    "            plt.subplot(1, 3, 2)\n",
    "            # plt.title(f\"label {i}\")\n",
    "            # plt.imshow(val_data[\"label\"][0, 0, :, :, slice])\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(f\"output {i}\")\n",
    "            # plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, slice])\n",
    "            plt.imshow(img_as_ubyte(out_img[0, 0, :, :, slice]))\n",
    "            plt.show()\n",
    "            fig.savefig(os.path.join(eval_saving_dir, f\"hipp_slice{slice}_{i}.png\"))\n",
    "            # Save the numpy array as well\n",
    "            np.save(os.path.join(eval_saving_dir, eval_file), out_img[0,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77bfc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, val_loader, device, slice=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ecf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, val_loader, device, slice=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, val_loader, device, slice=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a1af59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f45cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0415088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c05e114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d545a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c6591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edb2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54774174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912408c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78966a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f526ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dlunet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2348001f0bb3041eaa56551150bb0a090dab96d8a20a21dbf4b1734fdf432961"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
